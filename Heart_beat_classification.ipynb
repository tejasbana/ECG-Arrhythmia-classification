{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECG_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "QpH3QQUuNII4",
        "eZKs14vtr9jz",
        "1MciwboXmPHH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9V3qrI4ue2M9",
        "outputId": "66e705b7-bb99-475a-f92c-f22d0d32a6c7"
      },
      "source": [
        "# # Training - Testing splite shape\n",
        "# df_train = pd.read_csv(\"/content/mitbih.csv\", header=None)\n",
        "# df_train.shape\n",
        "# df_test = df_train.iloc[87554:,:]\n",
        "# df_train = df_train.iloc[:87554,:]\n",
        "# df_test.shape, df_train.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((21893, 188), (87554, 188))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GvePkLxe3lF",
        "outputId": "a307407d-5193-4c32-f493-cc5775894195"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
        "    concatenate, BatchNormalization\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# Training - Testing splite\n",
        "df_train = pd.read_csv(\"/content/heartbeat/mitbih_train.csv\", header=None)\n",
        "df_train = df_train.sample(frac=1)\n",
        "df_test = pd.read_csv(\"/content/heartbeat/mitbih_test.csv\", header=None)\n",
        "\n",
        "\n",
        "# Training inputes and target\n",
        "Y = np.array(df_train[187].values).astype(np.int8)\n",
        "X = np.array(df_train[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "# Testing inputes and target\n",
        "Y_test = np.array(df_test[187].values).astype(np.int8)\n",
        "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]\n",
        "\n",
        "# Model architecture\n",
        "def get_model():\n",
        "    nclass = 5\n",
        "    inp = Input(shape=(187, 1))\n",
        "    img_1 = Convolution1D(256, kernel_size=5, activation=activations.relu, padding=\"valid\")(inp)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=5, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(512, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = Convolution1D(512, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = Convolution1D(128, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.1)(img_1)\n",
        "    img_1 = Convolution1D(512, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = Convolution1D(512, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = BatchNormalization()(img_1)\n",
        "    img_1 = GlobalMaxPool1D()(img_1)\n",
        "    img_1 = Dropout(rate=0.2)(img_1)\n",
        "\n",
        "    dense_1 = Dense(256, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1 = BatchNormalization()(dense_1)\n",
        "    dense_1 = Dropout(rate=0.5)(dense_1)\n",
        "    dense_1 = Dense(128, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.softmax, name=\"dense_3_mitbih\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "# Load Model\n",
        "model = get_model()\n",
        "\n",
        "# Saving model checkpoints\n",
        "file_path = \"ecg_classification_model.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "\n",
        "# early stopping \n",
        "callbacks_list = [checkpoint, early, redonplat]  \n",
        "\n",
        "# Model training\n",
        "model.fit(X, Y, epochs=100, verbose=2, callbacks=callbacks_list, validation_split=0.1)\n",
        "model.load_weights(file_path)\n",
        "\n",
        "pred_test = model.predict(X_test)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "f1 = f1_score(Y_test, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y_test, pred_test)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 187, 1)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d_16 (Conv1D)           (None, 183, 256)          1536      \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 183, 256)          1024      \n",
            "_________________________________________________________________\n",
            "conv1d_17 (Conv1D)           (None, 179, 256)          327936    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 179, 256)          1024      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_6 (MaxPooling1 (None, 89, 256)           0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 89, 256)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_18 (Conv1D)           (None, 87, 512)           393728    \n",
            "_________________________________________________________________\n",
            "batch_normalization_20 (Batc (None, 87, 512)           2048      \n",
            "_________________________________________________________________\n",
            "conv1d_19 (Conv1D)           (None, 85, 512)           786944    \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 85, 512)           2048      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_7 (MaxPooling1 (None, 42, 512)           0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 42, 512)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 40, 128)           196736    \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 40, 128)           512       \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 38, 128)           49280     \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 38, 128)           512       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_8 (MaxPooling1 (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 19, 128)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 17, 512)           197120    \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 17, 512)           2048      \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 15, 512)           786944    \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 15, 512)           2048      \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_3_mitbih (Dense)       (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,917,381\n",
            "Trainable params: 2,911,237\n",
            "Non-trainable params: 6,144\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "2463/2463 - 40s - loss: 0.2582 - acc: 0.9276 - val_loss: 0.1633 - val_acc: 0.9596\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.95957, saving model to ecg_classification_model.h5\n",
            "Epoch 2/100\n",
            "2463/2463 - 38s - loss: 0.1420 - acc: 0.9612 - val_loss: 0.1411 - val_acc: 0.9627\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.95957 to 0.96265, saving model to ecg_classification_model.h5\n",
            "Epoch 3/100\n",
            "2463/2463 - 38s - loss: 0.1135 - acc: 0.9684 - val_loss: 0.1137 - val_acc: 0.9667\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.96265 to 0.96665, saving model to ecg_classification_model.h5\n",
            "Epoch 4/100\n",
            "2463/2463 - 38s - loss: 0.0976 - acc: 0.9724 - val_loss: 0.2377 - val_acc: 0.9243\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.96665\n",
            "Epoch 5/100\n",
            "2463/2463 - 38s - loss: 0.0880 - acc: 0.9750 - val_loss: 0.0704 - val_acc: 0.9792\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.96665 to 0.97921, saving model to ecg_classification_model.h5\n",
            "Epoch 6/100\n",
            "2463/2463 - 38s - loss: 0.0750 - acc: 0.9783 - val_loss: 0.0867 - val_acc: 0.9751\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.97921\n",
            "Epoch 7/100\n",
            "2463/2463 - 38s - loss: 0.0679 - acc: 0.9810 - val_loss: 0.0659 - val_acc: 0.9828\n",
            "\n",
            "Epoch 00007: val_acc improved from 0.97921 to 0.98275, saving model to ecg_classification_model.h5\n",
            "Epoch 8/100\n",
            "2463/2463 - 38s - loss: 0.0618 - acc: 0.9822 - val_loss: 0.1790 - val_acc: 0.9399\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.98275\n",
            "Epoch 9/100\n",
            "2463/2463 - 38s - loss: 0.0549 - acc: 0.9842 - val_loss: 0.0669 - val_acc: 0.9831\n",
            "\n",
            "Epoch 00009: val_acc improved from 0.98275 to 0.98310, saving model to ecg_classification_model.h5\n",
            "Epoch 10/100\n",
            "2463/2463 - 38s - loss: 0.0508 - acc: 0.9850 - val_loss: 0.2579 - val_acc: 0.9186\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.98310\n",
            "Epoch 11/100\n",
            "2463/2463 - 38s - loss: 0.0469 - acc: 0.9863 - val_loss: 0.1161 - val_acc: 0.9794\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.98310\n",
            "Epoch 12/100\n",
            "2463/2463 - 38s - loss: 0.0448 - acc: 0.9868 - val_loss: 0.0470 - val_acc: 0.9880\n",
            "\n",
            "Epoch 00012: val_acc improved from 0.98310 to 0.98801, saving model to ecg_classification_model.h5\n",
            "Epoch 13/100\n",
            "2463/2463 - 38s - loss: 0.0410 - acc: 0.9877 - val_loss: 0.2316 - val_acc: 0.9087\n",
            "\n",
            "Epoch 00013: val_acc did not improve from 0.98801\n",
            "Epoch 14/100\n",
            "2463/2463 - 38s - loss: 0.0386 - acc: 0.9884 - val_loss: 0.2976 - val_acc: 0.9372\n",
            "\n",
            "Epoch 00014: val_acc did not improve from 0.98801\n",
            "Epoch 15/100\n",
            "2463/2463 - 38s - loss: 0.0352 - acc: 0.9887 - val_loss: 0.0480 - val_acc: 0.9886\n",
            "\n",
            "Epoch 00015: val_acc improved from 0.98801 to 0.98858, saving model to ecg_classification_model.h5\n",
            "Epoch 16/100\n",
            "2463/2463 - 38s - loss: 0.0357 - acc: 0.9889 - val_loss: 0.0512 - val_acc: 0.9865\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.98858\n",
            "Epoch 17/100\n",
            "2463/2463 - 38s - loss: 0.0327 - acc: 0.9904 - val_loss: 0.0659 - val_acc: 0.9838\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.98858\n",
            "Epoch 18/100\n",
            "2463/2463 - 38s - loss: 0.0318 - acc: 0.9898 - val_loss: 0.1059 - val_acc: 0.9791\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.98858\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "Epoch 19/100\n",
            "2463/2463 - 38s - loss: 0.0242 - acc: 0.9927 - val_loss: 0.0459 - val_acc: 0.9893\n",
            "\n",
            "Epoch 00019: val_acc improved from 0.98858 to 0.98926, saving model to ecg_classification_model.h5\n",
            "Epoch 20/100\n",
            "2463/2463 - 38s - loss: 0.0172 - acc: 0.9943 - val_loss: 0.0442 - val_acc: 0.9896\n",
            "\n",
            "Epoch 00020: val_acc improved from 0.98926 to 0.98961, saving model to ecg_classification_model.h5\n",
            "Epoch 21/100\n",
            "2463/2463 - 38s - loss: 0.0153 - acc: 0.9952 - val_loss: 0.0494 - val_acc: 0.9901\n",
            "\n",
            "Epoch 00021: val_acc improved from 0.98961 to 0.99006, saving model to ecg_classification_model.h5\n",
            "Epoch 22/100\n",
            "2463/2463 - 38s - loss: 0.0142 - acc: 0.9953 - val_loss: 0.0482 - val_acc: 0.9895\n",
            "\n",
            "Epoch 00022: val_acc did not improve from 0.99006\n",
            "Epoch 23/100\n",
            "2463/2463 - 38s - loss: 0.0134 - acc: 0.9955 - val_loss: 0.0521 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00023: val_acc improved from 0.99006 to 0.99052, saving model to ecg_classification_model.h5\n",
            "Epoch 24/100\n",
            "2463/2463 - 38s - loss: 0.0117 - acc: 0.9960 - val_loss: 0.0521 - val_acc: 0.9896\n",
            "\n",
            "Epoch 00024: val_acc did not improve from 0.99052\n",
            "Epoch 25/100\n",
            "2463/2463 - 38s - loss: 0.0108 - acc: 0.9966 - val_loss: 0.0514 - val_acc: 0.9902\n",
            "\n",
            "Epoch 00025: val_acc did not improve from 0.99052\n",
            "Epoch 26/100\n",
            "2463/2463 - 38s - loss: 0.0111 - acc: 0.9963 - val_loss: 0.0495 - val_acc: 0.9903\n",
            "\n",
            "Epoch 00026: val_acc did not improve from 0.99052\n",
            "\n",
            "Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "Epoch 27/100\n",
            "2463/2463 - 38s - loss: 0.0104 - acc: 0.9965 - val_loss: 0.0487 - val_acc: 0.9903\n",
            "\n",
            "Epoch 00027: val_acc did not improve from 0.99052\n",
            "Epoch 28/100\n",
            "2463/2463 - 38s - loss: 0.0088 - acc: 0.9971 - val_loss: 0.0509 - val_acc: 0.9905\n",
            "\n",
            "Epoch 00028: val_acc did not improve from 0.99052\n",
            "Epoch 00028: early stopping\n",
            "Test f1 score : 0.9346838170319565 \n",
            "Test accuracy score : 0.9891741275351726 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpH3QQUuNII4"
      },
      "source": [
        "# Kera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS4Wf2-YsExX"
      },
      "source": [
        "# import torch\n",
        "# import torchvision\n",
        "import sklearn\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# import torch.nn.functional as F\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "import tensorflow as tf\n",
        "from keras import optimizers, losses, activations, models\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, Convolution1D, Dropout, MaxPool1D, GlobalAveragePooling1D, GlobalMaxPool1D, concatenate\n",
        "# from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRCYovxEtdfm"
      },
      "source": [
        "!pip install opendatasets --upgrade --quiet"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fi91xqMvtpXS",
        "outputId": "f2878664-91e6-4509-e16c-8ad18f5be9fb"
      },
      "source": [
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/shayanfazeli/heartbeat\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  5%|▌         | 5.00M/98.8M [00:00<00:03, 26.8MB/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading heartbeat.zip to ./heartbeat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 98.8M/98.8M [00:01<00:00, 71.1MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYx16a30tNKi"
      },
      "source": [
        "train_path = \"/content/heartbeat/mitbih_train.csv\"\n",
        "test_path  = \"/content/heartbeat/mitbih_test.csv\"\n",
        "train_df = pd.read_csv(train_path, header=None).sample(frac=1).reset_index(drop=True)\n",
        "test_df  = pd.read_csv(test_path , header=None).sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76x4vu2UeicV"
      },
      "source": [
        "pd.concat([train_df,test_df]).to_csv(\"mitbih.csv\",index=False)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ds36U87VuI_X",
        "outputId": "863ed63f-a056-4fb7-9824-275e63bbb41e"
      },
      "source": [
        "train_df.shape, test_df.shape, pd.concat([train_df,test_df])."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((87554, 188), (21892, 188), (109446, 188))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTUjPTz8uPYZ",
        "outputId": "4ead5790-06e2-4c6a-8abd-519a7d992e1d"
      },
      "source": [
        "train_df[187] = train_df[187].astype(int)\n",
        "equilibre = train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    90589\n",
            "4     8039\n",
            "2     7236\n",
            "1     2779\n",
            "3      803\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTFcIfq6B3aM"
      },
      "source": [
        "class_weight = {0: 0.01,\n",
        "                4: 0.1,\n",
        "                2: 0.11,\n",
        "                1: 0.2,\n",
        "                3: 0.58}"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0MZvcLr0iBP"
      },
      "source": [
        "# Balancing Out the Samples ratio\n",
        "df_0 = train_df[ train_df[187]==0 ].sample(n=10000, random_state=42)\n",
        "df_1 = train_df[ train_df[187]==1 ]\n",
        "df_2 = train_df[ train_df[187]==2 ]\n",
        "df_3 = train_df[ train_df[187]==3 ]\n",
        "df_4 = train_df[ train_df[187]==4 ]\n",
        "\n",
        "df_1_upsample = resample(df_1, n_samples=10000, replace=True, random_state=123)\n",
        "df_2_upsample = resample(df_2, n_samples=10000, replace=True, random_state=123)\n",
        "df_3_upsample = resample(df_3, n_samples=10000, replace=True, random_state=123)\n",
        "df_4_upsample = resample(df_4, n_samples=10000, replace=True, random_state=123)\n",
        "\n",
        "train_df = pd.concat([df_0, df_1_upsample, df_2_upsample, df_3_upsample, df_4_upsample])\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcQA4Fst3f4e",
        "outputId": "b03ad527-8131-4f8a-c637-77e1c0ffa1f0"
      },
      "source": [
        "equilibre = train_df[187].value_counts()\n",
        "print(equilibre)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4    10000\n",
            "3    10000\n",
            "2    10000\n",
            "1    10000\n",
            "0    10000\n",
            "Name: 187, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MO5EmHe2-DBr",
        "outputId": "27490b6b-277f-48ab-df4c-9269211683e9"
      },
      "source": [
        "train_df.shape"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3205, 188)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xli-tzUh8bMU"
      },
      "source": [
        "Y = np.array( train_df[187].values ).astype(np.int8)\n",
        "X = np.array( train_df[ list(range(187)) ].values)[..., np.newaxis]\n",
        "\n",
        "Y_test = np.array( test_df[187].values ).astype(np.int8)\n",
        "X_test = np.array( test_df[ list(range(187)) ].values ).astype(np.int8)[..., np.newaxis]"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WudXQQNw-fBH",
        "outputId": "0431f9aa-456e-42a7-e8c7-4076d061afa6"
      },
      "source": [
        "np.unique(Y_test, return_counts=True)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3, 4], dtype=int8),\n",
              " array([18118,   556,  1448,   162,  1608]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp1FKj30ANOu",
        "outputId": "a0c65063-a72d-4068-8a1d-9a8204438aab"
      },
      "source": [
        "X_test.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21892, 187, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRzdECbK4kgB",
        "outputId": "2362ce3e-a6e5-4a9c-a199-d8ab168aad8a"
      },
      "source": [
        "\n",
        "def get_model():\n",
        "    nclass = 5\n",
        "    inp = Input(shape=(187, 1))\n",
        "    img_1 = Convolution1D(16, kernel_size=3, activation=activations.relu, padding=\"valid\")(inp)\n",
        "    img_1 = Convolution1D(16, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.5)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=3, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.5)(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(32, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = MaxPool1D(pool_size=2)(img_1)\n",
        "    img_1 = Dropout(rate=0.5)(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = Convolution1D(256, kernel_size=2, activation=activations.relu, padding=\"valid\")(img_1)\n",
        "    img_1 = GlobalMaxPool1D()(img_1)\n",
        "    img_1 = Dropout(rate=0.5)(img_1)\n",
        "\n",
        "    dense_1 = Dense(512, activation=activations.relu, name=\"dense_1\")(img_1)\n",
        "    dense_1   = Dropout(rate=0.5)(dense_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_2\")(dense_1)\n",
        "    dense_1   = Dropout(rate=0.5)(dense_1)\n",
        "    dense_1 = Dense(512, activation=activations.relu, name=\"dense_3\")(dense_1)\n",
        "    dense_1   = Dropout(rate=0.5)(dense_1)\n",
        "    dense_1 = Dense(64, activation=activations.relu, name=\"dense_4\")(dense_1)\n",
        "    dense_1   = Dropout(rate=0.5)(dense_1)\n",
        "    dense_1 = Dense(nclass, activation=activations.softmax, name=\"dense_5_mitbih\")(dense_1)\n",
        "\n",
        "    model = models.Model(inputs=inp, outputs=dense_1)\n",
        "    opt = optimizers.Adam(0.0001)\n",
        "\n",
        "    model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "model = get_model()\n",
        "file_path = \"ecg.h5\"\n",
        "checkpoint = ModelCheckpoint(file_path, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)\n",
        "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)\n",
        "callbacks_list = [checkpoint, early, redonplat]  # early\n",
        "\n"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_8 (InputLayer)         [(None, 187, 1)]          0         \n",
            "_________________________________________________________________\n",
            "conv1d_56 (Conv1D)           (None, 185, 16)           64        \n",
            "_________________________________________________________________\n",
            "conv1d_57 (Conv1D)           (None, 183, 16)           784       \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 91, 16)            0         \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 91, 16)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_58 (Conv1D)           (None, 89, 32)            1568      \n",
            "_________________________________________________________________\n",
            "conv1d_59 (Conv1D)           (None, 87, 32)            3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 43, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 43, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_60 (Conv1D)           (None, 42, 32)            2080      \n",
            "_________________________________________________________________\n",
            "conv1d_61 (Conv1D)           (None, 41, 32)            2080      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 20, 32)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_62 (Conv1D)           (None, 19, 256)           16640     \n",
            "_________________________________________________________________\n",
            "conv1d_63 (Conv1D)           (None, 18, 256)           131328    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_7 (Glob (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               131584    \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "dropout_53 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_5_mitbih (Dense)       (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 388,501\n",
            "Trainable params: 388,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pwyabslC9hr",
        "outputId": "57d14070-3c5d-42a6-e4e8-3c417e3d6cc4"
      },
      "source": [
        "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device mapping:\n",
            "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P7oOfoJvDOTZ"
      },
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ywY_PKlD7NI"
      },
      "source": [
        "# For training on GPUs\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.keras import backend as K\n",
        "\n",
        "# adjust values to your needs\n",
        "config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 8} )\n",
        "sess = tf.compat.v1.Session(config=config) \n",
        "K.set_session(sess)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mbfekDr8-0S",
        "outputId": "f41379c5-30e1-4d68-bb7c-a2f7869e4009"
      },
      "source": [
        "model.fit(X, Y, epochs=100, verbose=2, callbacks=callbacks_list, validation_data=(X_test,Y_test))\n",
        "model.load_weights(file_path)\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "3421/3421 - 27s - loss: 0.6633 - acc: 0.8261 - val_loss: 0.9469 - val_acc: 0.8276\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.82761, saving model to ecg.h5\n",
            "Epoch 2/100\n",
            "3421/3421 - 25s - loss: 0.5249 - acc: 0.8300 - val_loss: 0.9576 - val_acc: 0.4289\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.82761\n",
            "Epoch 3/100\n",
            "3421/3421 - 25s - loss: 0.4818 - acc: 0.8430 - val_loss: 1.1239 - val_acc: 0.4290\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.82761\n",
            "Epoch 4/100\n",
            "3421/3421 - 25s - loss: 0.4528 - acc: 0.8642 - val_loss: 1.0638 - val_acc: 0.4515\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.82761\n",
            "\n",
            "Epoch 00004: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
            "Epoch 5/100\n",
            "3421/3421 - 25s - loss: 0.4307 - acc: 0.8746 - val_loss: 0.9162 - val_acc: 0.8271\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.82761\n",
            "Epoch 6/100\n",
            "3421/3421 - 25s - loss: 0.4263 - acc: 0.8758 - val_loss: 0.9102 - val_acc: 0.8271\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.82761\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xd8mNo9j9AkD",
        "outputId": "13417729-110e-4cc3-c807-25596d915e43"
      },
      "source": [
        "pred_test = model.predict(X)\n",
        "pred_test = np.argmax(pred_test, axis=-1)\n",
        "\n",
        "f1 = f1_score(Y, pred_test, average=\"macro\")\n",
        "\n",
        "print(\"Test f1 score : %s \"% f1)\n",
        "\n",
        "acc = accuracy_score(Y, pred_test)\n",
        "\n",
        "print(\"Test accuracy score : %s \"% acc)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test f1 score : 0.18114919543821278 \n",
            "Test accuracy score : 0.8277291728533248 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZKs14vtr9jz"
      },
      "source": [
        "# Noraml vs Abnormal autoencoders mlp\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZEkllpAeGBo"
      },
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTPqKsXgfWNL"
      },
      "source": [
        "# Hyperparameters\n",
        "batch_size=64\n",
        "\n",
        "\n",
        "# Other constants\n",
        "DATA_FILENAME_nor = \"Features.csv\"\n",
        "DATA_FILENAME_ab  = \"Features_ab.csv\"\n",
        "TARGET_COLUMN = 'class'\n",
        "output_size=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "u7xS_tz-fiYW",
        "outputId": "98cf2be9-cf49-4407-9890-e0a79338aaa8"
      },
      "source": [
        "# Read csv abnormal\n",
        "dataframe_ab = pd.read_csv(DATA_FILENAME_ab)\n",
        "dataframe_ab.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a1_mean</th>\n",
              "      <th>a1_var</th>\n",
              "      <th>a1_std</th>\n",
              "      <th>a2_mean</th>\n",
              "      <th>a2_var</th>\n",
              "      <th>a2_std</th>\n",
              "      <th>a3_mean</th>\n",
              "      <th>a3_var</th>\n",
              "      <th>a3_std</th>\n",
              "      <th>a4_mean</th>\n",
              "      <th>a4_var</th>\n",
              "      <th>a4_std</th>\n",
              "      <th>d3_mean</th>\n",
              "      <th>d3_var</th>\n",
              "      <th>d3_std</th>\n",
              "      <th>d4_mean</th>\n",
              "      <th>d4_var</th>\n",
              "      <th>d4_std</th>\n",
              "      <th>d5_mean</th>\n",
              "      <th>d5_var</th>\n",
              "      <th>d5_std</th>\n",
              "      <th>x_den_mean</th>\n",
              "      <th>x_den_var</th>\n",
              "      <th>x_den_std</th>\n",
              "      <th>RRavg</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.671785</td>\n",
              "      <td>0.283216</td>\n",
              "      <td>0.532181</td>\n",
              "      <td>0.946525</td>\n",
              "      <td>0.569203</td>\n",
              "      <td>0.754455</td>\n",
              "      <td>1.331620</td>\n",
              "      <td>1.148890</td>\n",
              "      <td>1.071863</td>\n",
              "      <td>1.851390</td>\n",
              "      <td>2.283045</td>\n",
              "      <td>1.510975</td>\n",
              "      <td>0.070535</td>\n",
              "      <td>0.004975</td>\n",
              "      <td>0.044549</td>\n",
              "      <td>0.168456</td>\n",
              "      <td>0.070517</td>\n",
              "      <td>0.265550</td>\n",
              "      <td>0.639755</td>\n",
              "      <td>0.932176</td>\n",
              "      <td>0.965493</td>\n",
              "      <td>0.240984</td>\n",
              "      <td>0.104556</td>\n",
              "      <td>0.323351</td>\n",
              "      <td>0.622396</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.591014</td>\n",
              "      <td>0.287352</td>\n",
              "      <td>0.536052</td>\n",
              "      <td>0.839874</td>\n",
              "      <td>0.576531</td>\n",
              "      <td>0.759296</td>\n",
              "      <td>1.200872</td>\n",
              "      <td>1.157578</td>\n",
              "      <td>1.075908</td>\n",
              "      <td>1.718517</td>\n",
              "      <td>2.226492</td>\n",
              "      <td>1.492143</td>\n",
              "      <td>0.065039</td>\n",
              "      <td>0.004230</td>\n",
              "      <td>0.035147</td>\n",
              "      <td>0.215432</td>\n",
              "      <td>0.120501</td>\n",
              "      <td>0.347132</td>\n",
              "      <td>0.831853</td>\n",
              "      <td>1.531993</td>\n",
              "      <td>1.237737</td>\n",
              "      <td>0.281985</td>\n",
              "      <td>0.148716</td>\n",
              "      <td>0.385637</td>\n",
              "      <td>0.613715</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.584377</td>\n",
              "      <td>0.354287</td>\n",
              "      <td>0.595220</td>\n",
              "      <td>0.827524</td>\n",
              "      <td>0.706405</td>\n",
              "      <td>0.840479</td>\n",
              "      <td>1.179446</td>\n",
              "      <td>1.404367</td>\n",
              "      <td>1.185060</td>\n",
              "      <td>1.670605</td>\n",
              "      <td>2.618803</td>\n",
              "      <td>1.618272</td>\n",
              "      <td>0.053585</td>\n",
              "      <td>0.002871</td>\n",
              "      <td>0.030339</td>\n",
              "      <td>0.221322</td>\n",
              "      <td>0.162561</td>\n",
              "      <td>0.403188</td>\n",
              "      <td>0.801195</td>\n",
              "      <td>1.537100</td>\n",
              "      <td>1.239798</td>\n",
              "      <td>0.297270</td>\n",
              "      <td>0.177098</td>\n",
              "      <td>0.420830</td>\n",
              "      <td>0.633333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.490090</td>\n",
              "      <td>0.351750</td>\n",
              "      <td>0.593085</td>\n",
              "      <td>0.692508</td>\n",
              "      <td>0.700777</td>\n",
              "      <td>0.837124</td>\n",
              "      <td>0.987181</td>\n",
              "      <td>1.389320</td>\n",
              "      <td>1.178694</td>\n",
              "      <td>1.401660</td>\n",
              "      <td>2.564609</td>\n",
              "      <td>1.601440</td>\n",
              "      <td>0.065972</td>\n",
              "      <td>0.004352</td>\n",
              "      <td>0.034596</td>\n",
              "      <td>0.217990</td>\n",
              "      <td>0.179694</td>\n",
              "      <td>0.423903</td>\n",
              "      <td>0.867769</td>\n",
              "      <td>1.814878</td>\n",
              "      <td>1.347174</td>\n",
              "      <td>0.282788</td>\n",
              "      <td>0.171519</td>\n",
              "      <td>0.414148</td>\n",
              "      <td>0.631852</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.622163</td>\n",
              "      <td>0.374982</td>\n",
              "      <td>0.612358</td>\n",
              "      <td>0.879827</td>\n",
              "      <td>0.745877</td>\n",
              "      <td>0.863642</td>\n",
              "      <td>1.248550</td>\n",
              "      <td>1.476280</td>\n",
              "      <td>1.215022</td>\n",
              "      <td>1.746414</td>\n",
              "      <td>2.692138</td>\n",
              "      <td>1.640774</td>\n",
              "      <td>0.053141</td>\n",
              "      <td>0.002824</td>\n",
              "      <td>0.029312</td>\n",
              "      <td>0.247523</td>\n",
              "      <td>0.205001</td>\n",
              "      <td>0.452770</td>\n",
              "      <td>0.971524</td>\n",
              "      <td>2.174858</td>\n",
              "      <td>1.474740</td>\n",
              "      <td>0.286924</td>\n",
              "      <td>0.187676</td>\n",
              "      <td>0.433216</td>\n",
              "      <td>0.648889</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0  0.671785  0.283216  0.532181  ...   0.323351  0.622396      0\n",
              "1  0.591014  0.287352  0.536052  ...   0.385637  0.613715      0\n",
              "2  0.584377  0.354287  0.595220  ...   0.420830  0.633333      0\n",
              "3  0.490090  0.351750  0.593085  ...   0.414148  0.631852      0\n",
              "4  0.622163  0.374982  0.612358  ...   0.433216  0.648889      0\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBkLiIt7fsmN",
        "outputId": "d9da6b94-8148-44c1-b577-50fcce0ee49c"
      },
      "source": [
        "dataframe_ab.count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of        a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0     0.671785  0.283216  0.532181  ...   0.323351  0.622396      0\n",
              "1     0.591014  0.287352  0.536052  ...   0.385637  0.613715      0\n",
              "2     0.584377  0.354287  0.595220  ...   0.420830  0.633333      0\n",
              "3     0.490090  0.351750  0.593085  ...   0.414148  0.631852      0\n",
              "4     0.622163  0.374982  0.612358  ...   0.433216  0.648889      0\n",
              "...        ...       ...       ...  ...        ...       ...    ...\n",
              "3055  0.573564  0.487619  0.698297  ...   0.492588  0.549228      0\n",
              "3056  0.502731  0.411116  0.641183  ...   0.473646  0.588235      0\n",
              "3057  0.725524  0.917416  0.957818  ...   0.596510  0.554938      0\n",
              "3058  0.580742  0.487073  0.697906  ...   0.510368  0.556046      0\n",
              "3059  0.651249  0.603792  0.777041  ...   0.559146  0.557026      0\n",
              "\n",
              "[3060 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "oMtAt6iXggaT",
        "outputId": "8af1908b-ce8e-47c7-edfb-e1c16d2a334f"
      },
      "source": [
        "# Read csv normal\n",
        "dataframe_nor = pd.read_csv(DATA_FILENAME_nor)\n",
        "dataframe_nor.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a1_mean</th>\n",
              "      <th>a1_var</th>\n",
              "      <th>a1_std</th>\n",
              "      <th>a2_mean</th>\n",
              "      <th>a2_var</th>\n",
              "      <th>a2_std</th>\n",
              "      <th>a3_mean</th>\n",
              "      <th>a3_var</th>\n",
              "      <th>a3_std</th>\n",
              "      <th>a4_mean</th>\n",
              "      <th>a4_var</th>\n",
              "      <th>a4_std</th>\n",
              "      <th>d3_mean</th>\n",
              "      <th>d3_var</th>\n",
              "      <th>d3_std</th>\n",
              "      <th>d4_mean</th>\n",
              "      <th>d4_var</th>\n",
              "      <th>d4_std</th>\n",
              "      <th>d5_mean</th>\n",
              "      <th>d5_var</th>\n",
              "      <th>d5_std</th>\n",
              "      <th>x_den_mean</th>\n",
              "      <th>x_den_var</th>\n",
              "      <th>x_den_std</th>\n",
              "      <th>RRavg</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.496333</td>\n",
              "      <td>0.057942</td>\n",
              "      <td>0.240712</td>\n",
              "      <td>0.696892</td>\n",
              "      <td>0.114536</td>\n",
              "      <td>0.338431</td>\n",
              "      <td>0.960112</td>\n",
              "      <td>0.180190</td>\n",
              "      <td>0.424488</td>\n",
              "      <td>1.280080</td>\n",
              "      <td>0.218380</td>\n",
              "      <td>0.467311</td>\n",
              "      <td>0.221602</td>\n",
              "      <td>0.049107</td>\n",
              "      <td>0.074602</td>\n",
              "      <td>0.169610</td>\n",
              "      <td>0.158507</td>\n",
              "      <td>0.398130</td>\n",
              "      <td>0.309862</td>\n",
              "      <td>0.242039</td>\n",
              "      <td>0.491975</td>\n",
              "      <td>0.080248</td>\n",
              "      <td>0.028684</td>\n",
              "      <td>0.169363</td>\n",
              "      <td>0.760897</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.493481</td>\n",
              "      <td>0.055499</td>\n",
              "      <td>0.235583</td>\n",
              "      <td>0.695676</td>\n",
              "      <td>0.109515</td>\n",
              "      <td>0.330930</td>\n",
              "      <td>0.972751</td>\n",
              "      <td>0.181975</td>\n",
              "      <td>0.426585</td>\n",
              "      <td>1.314298</td>\n",
              "      <td>0.199775</td>\n",
              "      <td>0.446962</td>\n",
              "      <td>0.188191</td>\n",
              "      <td>0.035416</td>\n",
              "      <td>0.061902</td>\n",
              "      <td>0.161193</td>\n",
              "      <td>0.158655</td>\n",
              "      <td>0.398316</td>\n",
              "      <td>0.302264</td>\n",
              "      <td>0.241258</td>\n",
              "      <td>0.491180</td>\n",
              "      <td>0.076618</td>\n",
              "      <td>0.027764</td>\n",
              "      <td>0.166625</td>\n",
              "      <td>0.811806</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.562665</td>\n",
              "      <td>0.064114</td>\n",
              "      <td>0.253208</td>\n",
              "      <td>0.794510</td>\n",
              "      <td>0.125810</td>\n",
              "      <td>0.354697</td>\n",
              "      <td>1.112134</td>\n",
              "      <td>0.219981</td>\n",
              "      <td>0.469021</td>\n",
              "      <td>1.497673</td>\n",
              "      <td>0.236369</td>\n",
              "      <td>0.486178</td>\n",
              "      <td>0.170943</td>\n",
              "      <td>0.029221</td>\n",
              "      <td>0.054653</td>\n",
              "      <td>0.178159</td>\n",
              "      <td>0.194435</td>\n",
              "      <td>0.440948</td>\n",
              "      <td>0.285753</td>\n",
              "      <td>0.225232</td>\n",
              "      <td>0.474586</td>\n",
              "      <td>0.081857</td>\n",
              "      <td>0.030558</td>\n",
              "      <td>0.174809</td>\n",
              "      <td>0.785185</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.561485</td>\n",
              "      <td>0.059060</td>\n",
              "      <td>0.243023</td>\n",
              "      <td>0.792288</td>\n",
              "      <td>0.115850</td>\n",
              "      <td>0.340367</td>\n",
              "      <td>1.099435</td>\n",
              "      <td>0.187675</td>\n",
              "      <td>0.433215</td>\n",
              "      <td>1.491555</td>\n",
              "      <td>0.215669</td>\n",
              "      <td>0.464402</td>\n",
              "      <td>0.204348</td>\n",
              "      <td>0.041758</td>\n",
              "      <td>0.065688</td>\n",
              "      <td>0.159914</td>\n",
              "      <td>0.151463</td>\n",
              "      <td>0.389183</td>\n",
              "      <td>0.266122</td>\n",
              "      <td>0.235398</td>\n",
              "      <td>0.485178</td>\n",
              "      <td>0.079103</td>\n",
              "      <td>0.028842</td>\n",
              "      <td>0.169829</td>\n",
              "      <td>0.771296</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.533408</td>\n",
              "      <td>0.063254</td>\n",
              "      <td>0.251503</td>\n",
              "      <td>0.750847</td>\n",
              "      <td>0.125129</td>\n",
              "      <td>0.353736</td>\n",
              "      <td>1.049855</td>\n",
              "      <td>0.209778</td>\n",
              "      <td>0.458015</td>\n",
              "      <td>1.409372</td>\n",
              "      <td>0.230862</td>\n",
              "      <td>0.480482</td>\n",
              "      <td>0.195499</td>\n",
              "      <td>0.038220</td>\n",
              "      <td>0.063987</td>\n",
              "      <td>0.178575</td>\n",
              "      <td>0.184014</td>\n",
              "      <td>0.428969</td>\n",
              "      <td>0.314236</td>\n",
              "      <td>0.242943</td>\n",
              "      <td>0.492892</td>\n",
              "      <td>0.082970</td>\n",
              "      <td>0.031648</td>\n",
              "      <td>0.177900</td>\n",
              "      <td>0.758120</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0  0.496333  0.057942  0.240712  ...   0.169363  0.760897      1\n",
              "1  0.493481  0.055499  0.235583  ...   0.166625  0.811806      1\n",
              "2  0.562665  0.064114  0.253208  ...   0.174809  0.785185      1\n",
              "3  0.561485  0.059060  0.243023  ...   0.169829  0.771296      1\n",
              "4  0.533408  0.063254  0.251503  ...   0.177900  0.758120      1\n",
              "\n",
              "[5 rows x 26 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6ttfiB_gr-v",
        "outputId": "de47a8f5-455d-409f-abfd-cf564429f978"
      },
      "source": [
        "dataframe_nor.count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of        a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0     0.496333  0.057942  0.240712  ...   0.169363  0.760897      1\n",
              "1     0.493481  0.055499  0.235583  ...   0.166625  0.811806      1\n",
              "2     0.562665  0.064114  0.253208  ...   0.174809  0.785185      1\n",
              "3     0.561485  0.059060  0.243023  ...   0.169829  0.771296      1\n",
              "4     0.533408  0.063254  0.251503  ...   0.177900  0.758120      1\n",
              "...        ...       ...       ...  ...        ...       ...    ...\n",
              "3595  0.500215  0.377247  0.614204  ...   0.376848  0.609896      1\n",
              "3596  0.406149  0.239154  0.489034  ...   0.306734  0.650370      1\n",
              "3597  0.426845  0.176651  0.420299  ...   0.298270  0.664074      1\n",
              "3598  0.422790  0.172482  0.415310  ...   0.288301  0.674206      1\n",
              "3599  0.493952  0.197787  0.444733  ...   0.310831  0.634815      1\n",
              "\n",
              "[3600 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Obqrc6hVrT",
        "outputId": "6a5afd2c-4486-499a-9fd1-854ae27e4595"
      },
      "source": [
        "extra_normal_data = dataframe_nor[3060:].copy()\n",
        "dataframe_nor = dataframe_nor[:3060].copy()\n",
        "\n",
        "dataframe_nor.count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of        a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0     0.496333  0.057942  0.240712  ...   0.169363  0.760897      1\n",
              "1     0.493481  0.055499  0.235583  ...   0.166625  0.811806      1\n",
              "2     0.562665  0.064114  0.253208  ...   0.174809  0.785185      1\n",
              "3     0.561485  0.059060  0.243023  ...   0.169829  0.771296      1\n",
              "4     0.533408  0.063254  0.251503  ...   0.177900  0.758120      1\n",
              "...        ...       ...       ...  ...        ...       ...    ...\n",
              "3055  0.366744  0.133120  0.364857  ...   0.257097  0.533951      1\n",
              "3056  0.348040  0.178243  0.422188  ...   0.296951  0.521930      1\n",
              "3057  0.378956  0.214903  0.463576  ...   0.325640  0.527623      1\n",
              "3058  0.371449  0.208434  0.456546  ...   0.324079  0.524415      1\n",
              "3059  0.411134  0.140770  0.375194  ...   0.256932  0.564706      1\n",
              "\n",
              "[3060 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM4Kp-VWfynJ"
      },
      "source": [
        "\n",
        "input_size= len(dataframe_ab.columns) - 1\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxX2CvpiiLRw",
        "outputId": "b432c8d9-2c79-41ff-e8a2-21598bd2fb5f"
      },
      "source": [
        "# Combining dataframe \n",
        "frame = [dataframe_nor , dataframe_ab]\n",
        "dataframe_combined = pd.concat(frame)\n",
        "dataframe_combined.count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of        a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0     0.496333  0.057942  0.240712  ...   0.169363  0.760897      1\n",
              "1     0.493481  0.055499  0.235583  ...   0.166625  0.811806      1\n",
              "2     0.562665  0.064114  0.253208  ...   0.174809  0.785185      1\n",
              "3     0.561485  0.059060  0.243023  ...   0.169829  0.771296      1\n",
              "4     0.533408  0.063254  0.251503  ...   0.177900  0.758120      1\n",
              "...        ...       ...       ...  ...        ...       ...    ...\n",
              "3055  0.573564  0.487619  0.698297  ...   0.492588  0.549228      0\n",
              "3056  0.502731  0.411116  0.641183  ...   0.473646  0.588235      0\n",
              "3057  0.725524  0.917416  0.957818  ...   0.596510  0.554938      0\n",
              "3058  0.580742  0.487073  0.697906  ...   0.510368  0.556046      0\n",
              "3059  0.651249  0.603792  0.777041  ...   0.559146  0.557026      0\n",
              "\n",
              "[6120 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqNN0kbXjG07",
        "outputId": "83a2e053-ba8d-4814-ae88-4506c3d75e33"
      },
      "source": [
        "# shuffle all the rows\n",
        "dataframe_combined = dataframe_combined.sample(frac=1).reset_index(drop=True)\n",
        "dataframe_combined.count"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method DataFrame.count of        a1_mean    a1_var    a1_std  ...  x_den_std     RRavg  Class\n",
              "0     0.266673  0.092384  0.303947  ...   0.215271  1.045679      1\n",
              "1     0.537247  0.656846  0.810460  ...   0.558964  0.559477      0\n",
              "2     1.418520  0.810018  0.900010  ...   0.636898  0.896465      0\n",
              "3     0.461480  0.049860  0.223293  ...   0.155661  0.680357      1\n",
              "4     0.477655  0.367650  0.606342  ...   0.451220  0.625000      0\n",
              "...        ...       ...       ...  ...        ...       ...    ...\n",
              "6115  0.476723  0.216170  0.464940  ...   0.367049  0.796065      1\n",
              "6116  1.270865  0.391017  0.625313  ...   0.444227  0.830093      0\n",
              "6117  0.309902  0.091421  0.302359  ...   0.190584  0.623611      0\n",
              "6118  1.336951  0.311333  0.557972  ...   0.391919  1.082099      0\n",
              "6119  0.495089  0.068347  0.261432  ...   0.182134  0.790741      1\n",
              "\n",
              "[6120 rows x 26 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbE1lYUcifgg",
        "outputId": "385ece87-a6c8-45e7-ffd3-81584a7ceca2"
      },
      "source": [
        "inputs = dataframe_combined.drop('Class', axis=1).values\n",
        "targets = dataframe_combined[['Class']].values\n",
        "\n",
        "inputs.shape , targets.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6120, 25), (6120, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrCHo1sAjnZ9"
      },
      "source": [
        "# Convert to Pytorch dataset\n",
        "torch.manual_seed(64)\n",
        "\n",
        "train_size = int(inputs.shape[0] * 0.8)\n",
        "val_size = inputs.shape[0] - train_size\n",
        "\n",
        "dataset = TensorDataset(torch.tensor(inputs , dtype=torch.float32), torch.tensor(targets, dtype=torch.float32))\n",
        "train_ds , val_ds = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size*2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MciwboXmPHH"
      },
      "source": [
        "# Logistic regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imlcjxKbmNVR"
      },
      "source": [
        "class EcgModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.network = nn.Sequential( nn.Linear(input_size, 512),\n",
        "                                      nn.BatchNorm1d(512),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                     \n",
        "                                      nn.Linear(512, 128),\n",
        "                                      nn.BatchNorm1d(128),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                     \n",
        "                                      nn.Linear(128, 512),\n",
        "                                      nn.BatchNorm1d(512),\n",
        "                                      nn.ReLU(inplace=True),\n",
        "                                     \n",
        "                                      nn.Linear(512, 1))\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        out = self.network(xb)\n",
        "        return torch.sigmoid(out)\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        out = self(inputs)                 # Generate predictions\n",
        "        loss = F.binary_cross_entropy(out, targets)    # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        inputs, targets = batch \n",
        "        out = self(inputs)                 # Generate predictions\n",
        "        # print(out.shape , targets.shape)\n",
        "        # print(out , targets)\n",
        "        loss = F.binary_cross_entropy(out, targets)    # Calculate loss\n",
        "        acc = accuracy(out , targets)                  # Calculating accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc' : acc.detach()}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc  = torch.stack(batch_accs).mean()     # Combine accuracy\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "    \n",
        "model = EcgModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQm9Iu0GmuBp"
      },
      "source": [
        "def accuracy(outputs, targets):\n",
        "  pred = torch.round(outputs)\n",
        "  return torch.tensor(torch.sum(pred == targets).item() / len(pred))\n",
        "\n",
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h3pjESQmzVi",
        "outputId": "192a7f97-b055-40fe-8b3d-2e9d8c937ed6"
      },
      "source": [
        " # Evaluate before training \n",
        "result = evaluate(model, val_loader)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.542100727558136, 'val_loss': 0.7107473611831665}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_vPxd94m3N_",
        "outputId": "7460bc5f-e1d8-450e-9b30-572113f77745"
      },
      "source": [
        "learning_rate=1e-2\n",
        "\n",
        "history = fit(25, learning_rate, model, train_loader, val_loader , opt_func=torch.optim.Adam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.3317, val_acc: 0.8602\n",
            "Epoch [1], val_loss: 0.2181, val_acc: 0.9164\n",
            "Epoch [2], val_loss: 0.1993, val_acc: 0.9182\n",
            "Epoch [3], val_loss: 0.1768, val_acc: 0.9304\n",
            "Epoch [4], val_loss: 0.1585, val_acc: 0.9321\n",
            "Epoch [5], val_loss: 0.1507, val_acc: 0.9470\n",
            "Epoch [6], val_loss: 0.1290, val_acc: 0.9527\n",
            "Epoch [7], val_loss: 0.1204, val_acc: 0.9550\n",
            "Epoch [8], val_loss: 0.1106, val_acc: 0.9591\n",
            "Epoch [9], val_loss: 0.1086, val_acc: 0.9583\n",
            "Epoch [10], val_loss: 0.0868, val_acc: 0.9652\n",
            "Epoch [11], val_loss: 0.0994, val_acc: 0.9585\n",
            "Epoch [12], val_loss: 0.1072, val_acc: 0.9607\n",
            "Epoch [13], val_loss: 0.0838, val_acc: 0.9681\n",
            "Epoch [14], val_loss: 0.0709, val_acc: 0.9767\n",
            "Epoch [15], val_loss: 0.0885, val_acc: 0.9714\n",
            "Epoch [16], val_loss: 0.0789, val_acc: 0.9679\n",
            "Epoch [17], val_loss: 0.0842, val_acc: 0.9713\n",
            "Epoch [18], val_loss: 0.0727, val_acc: 0.9713\n",
            "Epoch [19], val_loss: 0.0858, val_acc: 0.9697\n",
            "Epoch [20], val_loss: 0.0682, val_acc: 0.9730\n",
            "Epoch [21], val_loss: 0.0934, val_acc: 0.9694\n",
            "Epoch [22], val_loss: 0.0979, val_acc: 0.9674\n",
            "Epoch [23], val_loss: 0.1064, val_acc: 0.9618\n",
            "Epoch [24], val_loss: 0.0823, val_acc: 0.9703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZo5so0Pnt5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5049f79b-25d1-405a-b5aa-cb9c306cb93c"
      },
      "source": [
        "learning_rate=1e-3\n",
        "\n",
        "history += fit(30, learning_rate, model, train_loader, val_loader , opt_func=torch.optim.Adam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.0545, val_acc: 0.9783\n",
            "Epoch [1], val_loss: 0.0494, val_acc: 0.9828\n",
            "Epoch [2], val_loss: 0.0440, val_acc: 0.9838\n",
            "Epoch [3], val_loss: 0.0453, val_acc: 0.9838\n",
            "Epoch [4], val_loss: 0.0486, val_acc: 0.9785\n",
            "Epoch [5], val_loss: 0.0437, val_acc: 0.9806\n",
            "Epoch [6], val_loss: 0.0459, val_acc: 0.9820\n",
            "Epoch [7], val_loss: 0.0436, val_acc: 0.9838\n",
            "Epoch [8], val_loss: 0.0453, val_acc: 0.9838\n",
            "Epoch [9], val_loss: 0.0420, val_acc: 0.9822\n",
            "Epoch [10], val_loss: 0.0421, val_acc: 0.9845\n",
            "Epoch [11], val_loss: 0.0457, val_acc: 0.9822\n",
            "Epoch [12], val_loss: 0.0393, val_acc: 0.9852\n",
            "Epoch [13], val_loss: 0.0396, val_acc: 0.9844\n",
            "Epoch [14], val_loss: 0.0344, val_acc: 0.9891\n",
            "Epoch [15], val_loss: 0.0362, val_acc: 0.9859\n",
            "Epoch [16], val_loss: 0.0415, val_acc: 0.9852\n",
            "Epoch [17], val_loss: 0.0376, val_acc: 0.9883\n",
            "Epoch [18], val_loss: 0.0377, val_acc: 0.9867\n",
            "Epoch [19], val_loss: 0.0366, val_acc: 0.9853\n",
            "Epoch [20], val_loss: 0.0341, val_acc: 0.9867\n",
            "Epoch [21], val_loss: 0.0342, val_acc: 0.9852\n",
            "Epoch [22], val_loss: 0.0372, val_acc: 0.9883\n",
            "Epoch [23], val_loss: 0.0421, val_acc: 0.9875\n",
            "Epoch [24], val_loss: 0.0360, val_acc: 0.9844\n",
            "Epoch [25], val_loss: 0.0346, val_acc: 0.9861\n",
            "Epoch [26], val_loss: 0.0391, val_acc: 0.9859\n",
            "Epoch [27], val_loss: 0.0376, val_acc: 0.9861\n",
            "Epoch [28], val_loss: 0.0368, val_acc: 0.9845\n",
            "Epoch [29], val_loss: 0.0378, val_acc: 0.9867\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rS_DyeglUqNM",
        "outputId": "eeaa6106-b41b-413f-c681-d31f34c43865"
      },
      "source": [
        "learning_rate=1e-4\n",
        "\n",
        "history += fit(4, learning_rate, model, train_loader, val_loader , opt_func=torch.optim.Adam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.0356, val_acc: 0.9883\n",
            "Epoch [1], val_loss: 0.0342, val_acc: 0.9875\n",
            "Epoch [2], val_loss: 0.0332, val_acc: 0.9867\n",
            "Epoch [3], val_loss: 0.0335, val_acc: 0.9875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKhqC2NDU_dG",
        "outputId": "4c55b17e-a078-45be-8748-9fda7c180478"
      },
      "source": [
        "learning_rate=8e-5\n",
        "\n",
        "history += fit(10, learning_rate, model, train_loader, val_loader , opt_func=torch.optim.Adam)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.0329, val_acc: 0.9867\n",
            "Epoch [1], val_loss: 0.0323, val_acc: 0.9875\n",
            "Epoch [2], val_loss: 0.0324, val_acc: 0.9867\n",
            "Epoch [3], val_loss: 0.0325, val_acc: 0.9867\n",
            "Epoch [4], val_loss: 0.0321, val_acc: 0.9867\n",
            "Epoch [5], val_loss: 0.0326, val_acc: 0.9875\n",
            "Epoch [6], val_loss: 0.0326, val_acc: 0.9875\n",
            "Epoch [7], val_loss: 0.0320, val_acc: 0.9891\n",
            "Epoch [8], val_loss: 0.0319, val_acc: 0.9891\n",
            "Epoch [9], val_loss: 0.0318, val_acc: 0.9898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Yl6MQK9KVNDH",
        "outputId": "86bdd757-bfc3-4f16-808c-064a179367f9"
      },
      "source": [
        "acc = [x['val_acc'] for x in history]\n",
        "loss = [x['val_loss'] for x in history]\n",
        "plt.plot(acc)\n",
        "plt.title(\"Accuracy vs Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "91tUMSI4WTOQ",
        "outputId": "c17c8823-04f4-4819-ac44-d95619685e1e"
      },
      "source": [
        "plt.plot(loss)\n",
        "plt.title(\"loss vs Epoch\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbW63-ZzYI0W",
        "outputId": "b45f74b3-8856-4941-8ba3-d802796c1e1a"
      },
      "source": [
        " # Evaluate after training on validation data\n",
        "result = evaluate(model, val_loader)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.9898437261581421, 'val_loss': 0.031839050352573395}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_nZlSDpYrWk",
        "outputId": "3347c2d0-a1da-4319-aee8-c12d76109c02"
      },
      "source": [
        "# Evaluate after training on training data\n",
        "result = evaluate(model, train_loader)\n",
        "result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.9951298832893372, 'val_loss': 0.015356208197772503}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZzDaduLYxXx"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "import gc\n",
        "import time\n",
        "import os\n",
        "import matplotlib\n",
        "import datetime\n",
        "import h5py\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import balanced_accuracy_score,classification_report,plot_confusion_matrix\n",
        "from sklearn.model_selection import KFold # kfold cross validation\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from glob import glob\n",
        "import datetime\n",
        "import gc\n",
        "import sklearn\n",
        "import sklearn.preprocessing as preprocessing\n",
        "\n",
        "import tensorflow.keras as keras \n",
        "\n",
        "tf.compat.v1.enable_eager_execution()\n",
        "K.clear_session()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "def main(training: str, validation: str, splits: int = 10):\n",
        "    g = h5py.File(validation, 'r')\n",
        "    f = h5py.File(training, 'r')\n",
        "\n",
        "    enc = preprocessing.OneHotEncoder()\n",
        "\n",
        "    x_tmp = np.array(g[\"REALS\"])\n",
        "    y_tmp = np.array(g[\"REALS_ann\"])\n",
        "\n",
        "    val_dataset_x, val_dataset_y = x_tmp, enc.fit_transform(y_tmp.reshape(-1,1)).toarray()\n",
        "\n",
        "    x = g['REALS']\n",
        "    y = g['REALS_ann']\n",
        "\n",
        "    X, Y = f[\"X\"], f[\"Y\"]\n",
        "\n",
        "    # split into k folds\n",
        "    kfold = StratifiedKFold(n_splits=splits, shuffle=True)\n",
        "\n",
        "    # TRAIN\n",
        "    counter = 0\n",
        "    hists = []\n",
        "    for train_index, test_index in kfold.split(X, Y):\n",
        "        # model\n",
        "        model, callbacks = resnet(f\"raw_training_{counter}.log\", classes=8, init_lr=0.1, tensorboard_dir=\"logs/\")\n",
        "        # split\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = Y[train_index], Y[test_index]\n",
        "\n",
        "        y_train = enc.transform(y_train).toarray()\n",
        "        y_test = enc.transform(y_test).toarray()\n",
        "        # fit\n",
        "        hist = model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), callbacks=callbacks,shuffle=True, batch_size=256, epochs=150)\n",
        "\n",
        "        counter += 1\n",
        "        hists.append(hist)\n",
        "\n",
        "    ## TEST DATA\n",
        "    model = resnet(f\"raw_training_final.log\", classes=8, init_lr=0.1, tensorboard_dir=\"logs/\")\n",
        "    preds = model.predict(val_dataset_x)\n",
        "\n",
        "    model.save(\"final_fold_model.hdf5\")\n",
        "\n",
        "\n",
        "    # WITHOUT KFOLD\n",
        "    \"\"\"y = enc.transform(np.array(y)).toarray()\n",
        "    x_train,x_test,y_train,y_test = sklearn.model_selection.train_test_split(np.array(x),np.array(y),test_size=0.2)\n",
        "    # save the split\n",
        "    np.save(\"raw_x_train.npy\", x_train)\n",
        "    np.save(\"raw_y_train.npy\", y_train)\n",
        "    np.save(\"raw_x_test.npy\", x_test)\n",
        "    np.save(\"raw_y_test.npy\", y_test)\n",
        "    model, callbacks = resnet(f\"raw_training.log\", classes=9, init_lr=0.1, tensorboard_dir=\"logs/\")\n",
        "    y_test = enc.transform(y_test).toarray()\n",
        "    y_train = enc.transform(y_train).toarray()\n",
        "    hist = model.fit(x=x_train, y=y_train, validation_data=(x_test, y_test), callbacks=callbacks,shuffle=True, batch_size=256, epochs=150)\"\"\"\n",
        "\n",
        "    \n",
        "\n",
        "def combine(d: h5py.File, enc: preprocessing.OneHotEncoder = None) -> (np.ndarray, np.ndarray):\n",
        "\n",
        "    if enc is not None:\n",
        "        out_X, out_Y = [], []\n",
        "        dfs = list(d.keys())\n",
        "        for df in dfs:\n",
        "            if '_ann' not in df:\n",
        "                anns = d[df+\"_ann\"]\n",
        "                for n,xx in enumerate(d[df]):\n",
        "                    out_X.append(xx)\n",
        "                    out_Y.append(enc.transform(anns[n].reshape((-1,1))).toarray())\n",
        "    else:\n",
        "        out_X, out_Y = [], []\n",
        "        dfs = list(d.keys())\n",
        "        for df in dfs:\n",
        "            if '_ann' not in df:\n",
        "                anns = d[df+\"_ann\"]\n",
        "                for n,xx in enumerate(d[df]):\n",
        "                    out_X.append(xx)\n",
        "                    out_Y.append(anns[n])\n",
        "    return (np.array(out_X), np.array(out_Y))\n",
        "\n",
        "\n",
        "def resnet(training_log_path: str, classes: int, init_lr: float, tensorboard_dir: str, n_feature_maps: int=64):\n",
        "    \n",
        "    class_names = [\"Normal\",\"RBBB\",\"PVC\", \"FUSION\", \"APC\", \"SVPB\", \"NESC\",\"UNKNOWN\", \"SVESC\"]\n",
        "    def single_class_accuracy(interesting_class_id):\n",
        "        # compute the accuracy of a single class\n",
        "        def fn(y_true, y_pred):\n",
        "            class_id_true = K.argmax(y_true, axis=-1)\n",
        "            class_id_preds = K.argmax(y_pred, axis=-1)\n",
        "            accuracy_mask = K.cast(K.equal(class_id_preds, interesting_class_id), 'int32')\n",
        "            class_acc_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * accuracy_mask\n",
        "            class_acc = K.sum(class_acc_tensor) / K.maximum(K.sum(accuracy_mask), 1)\n",
        "            return class_acc\n",
        "        return fn\n",
        "\n",
        "    class CustomCallback(Callback):\n",
        "        def __init__(self):\n",
        "            self.dat = []\n",
        "            self.seen = 0\n",
        "            self.epoch = 1\n",
        "        def on_batch_end(self,batch,logs={}):\n",
        "            self.dat = logs\n",
        "\n",
        "        def on_epoch_end(self,batch,logs={}):\n",
        "            np.save(f\"epoch_dat_{self.epoch}.npy\", self.dat, allow_pickle=True)\n",
        "            self.epoch += 1\n",
        "            gc.collect() # try to clear up some memory??\n",
        "\n",
        "\n",
        "    METRICS = [\n",
        "        keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "        keras.metrics.Precision(name='precision'),\n",
        "        keras.metrics.Recall(name='recall'),\n",
        "        keras.metrics.AUC(name='auc')\n",
        "    ]\n",
        "\n",
        "    input_layer = keras.layers.Input((339,12),dtype='float32')\n",
        "\n",
        "    conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "    conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "    conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "    # expand channels for the sum\n",
        "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
        "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
        "    output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
        "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "    shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
        "    shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
        "    output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
        "    output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
        "    conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
        "    conv_x = keras.layers.BatchNormalization()(conv_x)\n",
        "    conv_x = keras.layers.Activation('relu')(conv_x)\n",
        "    conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
        "    conv_y = keras.layers.BatchNormalization()(conv_y)\n",
        "    conv_y = keras.layers.Activation('relu')(conv_y)\n",
        "    conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
        "    conv_z = keras.layers.BatchNormalization()(conv_z)\n",
        "    # no need to expand channels because they are equal\n",
        "    shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
        "    output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
        "    output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
        "\n",
        "    gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
        "\n",
        "    output_layer = keras.layers.Dense(classes, activation='softmax')(gap_layer)\n",
        "    model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\t\n",
        "    def my_sparse_categorical_crossentropy(y_true, y_pred): # need from logits TRUE override default\n",
        "        return K.categorical_crossentropy(y_true, y_pred, from_logits=False)\n",
        "\n",
        "    class spec(tf.keras.metrics.Metric):\n",
        "\n",
        "        def __init__(self,name, typea,**kwargs):\n",
        "            super(spec, self).__init__(name=name, **kwargs)\n",
        "            self.typea = typea\n",
        "\n",
        "        def update_state(self, y_true, y_pred,sample_weight=None):\n",
        "            class_id_true = K.argmax(y_true, axis=-1) # one-hot -> int\n",
        "            class_id_preds = K.argmax(y_pred, axis=-1)\n",
        "            recall_mask = K.cast(K.equal(class_id_true, self.typea), 'int32')\n",
        "            class_recall_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * recall_mask\n",
        "            self.tmp = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
        "            tf.cond(K.cast(K.equal(K.cast(self.tmp, tf.float64), tf.constant(0.0, dtype=tf.float64)),dtype=tf.bool),true_fn=self.if_true, false_fn=self.if_false)\n",
        "\n",
        "        def result(self):\n",
        "            return tf.math.subtract(tf.constant(1.0, dtype=tf.float64), self.recall)\n",
        "\n",
        "        def if_false(self):\n",
        "            self.recall = self.tmp\n",
        "\n",
        "    class sens(tf.keras.metrics.Metric):\n",
        "    # sensitivity metric\n",
        "        def __init__(self,name, typea,**kwargs):\n",
        "            super(sens, self).__init__(name=name, **kwargs)\n",
        "            self.typea = typea\n",
        "\n",
        "        def update_state(self, y_true, y_pred,sample_weight=None):\n",
        "            class_id_true = K.argmax(y_true, axis=-1) # one-hot -> int\n",
        "            class_id_preds = K.argmax(y_pred, axis=-1)\n",
        "            recall_mask = K.cast(K.equal(class_id_true, self.typea), 'int32')\n",
        "            class_recall_tensor = K.cast(K.equal(class_id_true, class_id_preds), 'int32') * recall_mask\n",
        "            self.tmp = K.sum(class_recall_tensor) / K.maximum(K.sum(recall_mask), 1)\n",
        "            tf.cond(K.cast(K.equal(K.cast(self.tmp, tf.float64), tf.constant(0.0, dtype=tf.float64)),dtype=tf.bool),true_fn=self.if_true, false_fn=self.if_false) # only update recall if not = 0, pesty that it resets if self.typea not in the current batch\n",
        "\n",
        "        def if_false(self):\n",
        "            self.recall = self.tmp\n",
        "\n",
        "\n",
        "    model.compile(loss=my_sparse_categorical_crossentropy, optimizer=keras.optimizers.SGD(lr=init_lr),metrics=[m for m in METRICS], weighted_metrics=[\"accuracy\"])\n",
        "\n",
        "    reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=4, min_lr=0.0000001)\n",
        "\n",
        "    file_path = f'raw_train_aug_{str(datetime.datetime.now())}.hdf5'\n",
        "    cc = CustomCallback()\n",
        "\n",
        "    model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, min_delta=1e-4)\n",
        "\n",
        "    csv = tf.keras.callbacks.CSVLogger(training_log_path, separator=\",\", append=False)\n",
        "\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(f\"{tensorboard_dir}/model\"+str(datetime.datetime.now()), histogram_freq=1, update_freq=\"batch\")\n",
        "\n",
        "    callbacksa = [reduce_lr, model_checkpoint, callback, cc, csv, tensorboard_callback]\n",
        "\n",
        "    return (model, callbacksa)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\tmain(\"training\", \"reals\")\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}