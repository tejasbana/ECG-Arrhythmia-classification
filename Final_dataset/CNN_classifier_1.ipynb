{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers, losses, activations, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate, BatchNormalization\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"D:/COEP/Project/Main/Final Review/Dataset/mitbih_train.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>178</th>\n",
       "      <th>179</th>\n",
       "      <th>180</th>\n",
       "      <th>181</th>\n",
       "      <th>182</th>\n",
       "      <th>183</th>\n",
       "      <th>184</th>\n",
       "      <th>185</th>\n",
       "      <th>186</th>\n",
       "      <th>187</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.977941</td>\n",
       "      <td>0.926471</td>\n",
       "      <td>0.681373</td>\n",
       "      <td>0.245098</td>\n",
       "      <td>0.154412</td>\n",
       "      <td>0.191176</td>\n",
       "      <td>0.151961</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.049020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.960114</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>0.125356</td>\n",
       "      <td>0.099715</td>\n",
       "      <td>0.088319</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.082621</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659459</td>\n",
       "      <td>0.186486</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.070270</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.056757</td>\n",
       "      <td>0.043243</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.925414</td>\n",
       "      <td>0.665746</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.276243</td>\n",
       "      <td>0.196133</td>\n",
       "      <td>0.077348</td>\n",
       "      <td>0.071823</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.066298</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.967136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.586854</td>\n",
       "      <td>0.356808</td>\n",
       "      <td>0.248826</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.117371</td>\n",
       "      <td>0.150235</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87549</th>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.494737</td>\n",
       "      <td>0.536842</td>\n",
       "      <td>0.529825</td>\n",
       "      <td>0.491228</td>\n",
       "      <td>0.484211</td>\n",
       "      <td>0.456140</td>\n",
       "      <td>0.396491</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.136842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87550</th>\n",
       "      <td>0.718333</td>\n",
       "      <td>0.605000</td>\n",
       "      <td>0.486667</td>\n",
       "      <td>0.361667</td>\n",
       "      <td>0.231667</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.051667</td>\n",
       "      <td>0.001667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87551</th>\n",
       "      <td>0.906122</td>\n",
       "      <td>0.624490</td>\n",
       "      <td>0.595918</td>\n",
       "      <td>0.575510</td>\n",
       "      <td>0.530612</td>\n",
       "      <td>0.481633</td>\n",
       "      <td>0.444898</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.322449</td>\n",
       "      <td>0.191837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87552</th>\n",
       "      <td>0.858228</td>\n",
       "      <td>0.645570</td>\n",
       "      <td>0.845570</td>\n",
       "      <td>0.248101</td>\n",
       "      <td>0.167089</td>\n",
       "      <td>0.131646</td>\n",
       "      <td>0.121519</td>\n",
       "      <td>0.121519</td>\n",
       "      <td>0.118987</td>\n",
       "      <td>0.103797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87553</th>\n",
       "      <td>0.901506</td>\n",
       "      <td>0.845886</td>\n",
       "      <td>0.800695</td>\n",
       "      <td>0.748552</td>\n",
       "      <td>0.687138</td>\n",
       "      <td>0.599073</td>\n",
       "      <td>0.512167</td>\n",
       "      <td>0.427578</td>\n",
       "      <td>0.395133</td>\n",
       "      <td>0.402086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87554 rows Ã— 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.977941  0.926471  0.681373  0.245098  0.154412  0.191176  0.151961   \n",
       "1      0.960114  0.863248  0.461538  0.196581  0.094017  0.125356  0.099715   \n",
       "2      1.000000  0.659459  0.186486  0.070270  0.070270  0.059459  0.056757   \n",
       "3      0.925414  0.665746  0.541436  0.276243  0.196133  0.077348  0.071823   \n",
       "4      0.967136  1.000000  0.830986  0.586854  0.356808  0.248826  0.145540   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "87549  0.807018  0.494737  0.536842  0.529825  0.491228  0.484211  0.456140   \n",
       "87550  0.718333  0.605000  0.486667  0.361667  0.231667  0.120000  0.051667   \n",
       "87551  0.906122  0.624490  0.595918  0.575510  0.530612  0.481633  0.444898   \n",
       "87552  0.858228  0.645570  0.845570  0.248101  0.167089  0.131646  0.121519   \n",
       "87553  0.901506  0.845886  0.800695  0.748552  0.687138  0.599073  0.512167   \n",
       "\n",
       "            7         8         9    ...  178  179  180  181  182  183  184  \\\n",
       "0      0.085784  0.058824  0.049020  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1      0.088319  0.074074  0.082621  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.043243  0.054054  0.045946  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      0.060773  0.066298  0.058011  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4      0.089202  0.117371  0.150235  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "87549  0.396491  0.284211  0.136842  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87550  0.001667  0.000000  0.013333  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87551  0.387755  0.322449  0.191837  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87552  0.121519  0.118987  0.103797  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "87553  0.427578  0.395133  0.402086  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       185  186  187  \n",
       "0      0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  \n",
       "3      0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  \n",
       "...    ...  ...  ...  \n",
       "87549  0.0  0.0  4.0  \n",
       "87550  0.0  0.0  4.0  \n",
       "87551  0.0  0.0  4.0  \n",
       "87552  0.0  0.0  4.0  \n",
       "87553  0.0  0.0  4.0  \n",
       "\n",
       "[87554 rows x 188 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"D:/COEP/Project/Main/Final Review/Dataset/mitbih_test.csv\", header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58281    0.0\n",
       "41253    0.0\n",
       "23869    0.0\n",
       "7631     0.0\n",
       "39898    0.0\n",
       "        ... \n",
       "24991    0.0\n",
       "29362    0.0\n",
       "24239    0.0\n",
       "57688    0.0\n",
       "53743    0.0\n",
       "Name: 187, Length: 72471, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[187]==0][187]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72750    1.0\n",
       "73808    1.0\n",
       "74326    1.0\n",
       "73780    1.0\n",
       "74660    1.0\n",
       "        ... \n",
       "74376    1.0\n",
       "73053    1.0\n",
       "74448    1.0\n",
       "74341    1.0\n",
       "73426    1.0\n",
       "Name: 187, Length: 2223, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[187]==1][187]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RBBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76286    2.0\n",
       "80354    2.0\n",
       "79181    2.0\n",
       "76794    2.0\n",
       "80223    2.0\n",
       "        ... \n",
       "78558    2.0\n",
       "74931    2.0\n",
       "75986    2.0\n",
       "77280    2.0\n",
       "77435    2.0\n",
       "Name: 187, Length: 5788, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[187]==2][187]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80864    3.0\n",
       "81052    3.0\n",
       "81057    3.0\n",
       "80779    3.0\n",
       "80645    3.0\n",
       "        ... \n",
       "80825    3.0\n",
       "80798    3.0\n",
       "80672    3.0\n",
       "80962    3.0\n",
       "80932    3.0\n",
       "Name: 187, Length: 641, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[187]==3][187]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82130    4.0\n",
       "85090    4.0\n",
       "85496    4.0\n",
       "86421    4.0\n",
       "87348    4.0\n",
       "        ... \n",
       "84780    4.0\n",
       "82254    4.0\n",
       "82451    4.0\n",
       "81150    4.0\n",
       "86382    4.0\n",
       "Name: 187, Length: 6431, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[df_train[187]==4][187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[187].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(df_train[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(df_train[187].values).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(df_test[list(range(187))].values)[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = np.array(df_test[187].values).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    " nclass = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_im = Input(shape=(187, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(128, kernel_size=5, activation=activations.relu, padding=\"valid\")(input_im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(128, kernel_size=5, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = MaxPool1D(pool_size=2)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Dropout(rate=0.1)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = MaxPool1D(pool_size=2)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Dropout(rate=0.1)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(64, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = MaxPool1D(pool_size=2)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Dropout(rate=0.1)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Convolution1D(256, kernel_size=3, activation=activations.relu, padding=\"valid\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = BatchNormalization()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = GlobalMaxPool1D()(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Dropout(rate=0.2)(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dense(128, activation=activations.relu, name=\"d1\")(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = BatchNormalization()(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dropout(rate=0.5)(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dense(64, activation=activations.relu, name=\"d2\")(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dense(nclass, activation=activations.softmax, name=\"d3_arr\")(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=input_im, outputs=d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=opt, loss=losses.sparse_categorical_crossentropy, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 187, 1)]          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 183, 128)          768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 183, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 179, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 179, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 89, 128)           0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 89, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 87, 256)           98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 87, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 85, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 85, 256)           1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 42, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 42, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 40, 64)            49216     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 40, 64)            256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 38, 64)            12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 38, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 19, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 17, 256)           49408     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 17, 256)           1024      \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "d1 (Dense)                   (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "d2 (Dense)                   (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "d3_arr (Dense)               (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 733,701\n",
      "Trainable params: 730,629\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_pnt_filepath = \"Beat_CLassification_Model.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ModelCheckpoint : Saves a model or weights in a file do that the model or weights can be loaded at a later point in time and training can be continued.\n",
    "\n",
    "https://keras.io/api/callbacks/model_checkpoint/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_pnt = ModelCheckpoint(chk_pnt_filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Early Stopping: Stops training when a monitored metric has stopped improving over a specified number of epochs\n",
    "\n",
    "https://www.ironmanjohn.com/home/i-love-keras-earlystopping\n",
    "\n",
    "https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduces learning rate by a factor when there is no improvement in the specified metric over the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdlp = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [chk_pnt, early, rdlp]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2463/2463 - 344s - loss: 0.3017 - acc: 0.9136 - val_loss: 0.1783 - val_acc: 0.9512\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.95123, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 2/100\n",
      "2463/2463 - 339s - loss: 0.1644 - acc: 0.9557 - val_loss: 0.2901 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.95123\n",
      "Epoch 3/100\n",
      "2463/2463 - 339s - loss: 0.1313 - acc: 0.9649 - val_loss: 0.1075 - val_acc: 0.9690\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.95123 to 0.96905, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 4/100\n",
      "2463/2463 - 355s - loss: 0.1121 - acc: 0.9696 - val_loss: 0.1058 - val_acc: 0.9703\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.96905 to 0.97031, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 5/100\n",
      "2463/2463 - 345s - loss: 0.0954 - acc: 0.9735 - val_loss: 0.0691 - val_acc: 0.9794\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.97031 to 0.97944, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 6/100\n",
      "2463/2463 - 339s - loss: 0.0888 - acc: 0.9755 - val_loss: 0.0922 - val_acc: 0.9766\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.97944\n",
      "Epoch 7/100\n",
      "2463/2463 - 340s - loss: 0.0760 - acc: 0.9784 - val_loss: 0.0681 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.97944 to 0.98230, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 8/100\n",
      "2463/2463 - 342s - loss: 0.0721 - acc: 0.9798 - val_loss: 0.0609 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.98230\n",
      "Epoch 9/100\n",
      "2463/2463 - 315s - loss: 0.0643 - acc: 0.9818 - val_loss: 0.0627 - val_acc: 0.9815\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.98230\n",
      "Epoch 10/100\n",
      "2463/2463 - 4103s - loss: 0.0583 - acc: 0.9832 - val_loss: 0.0514 - val_acc: 0.9860\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.98230 to 0.98595, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 11/100\n",
      "2463/2463 - 339s - loss: 0.0562 - acc: 0.9841 - val_loss: 0.0457 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.98595 to 0.98687, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 12/100\n",
      "2463/2463 - 337s - loss: 0.0536 - acc: 0.9845 - val_loss: 0.0519 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.98687\n",
      "Epoch 13/100\n",
      "2463/2463 - 337s - loss: 0.0502 - acc: 0.9855 - val_loss: 0.0627 - val_acc: 0.9821\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.98687\n",
      "Epoch 14/100\n",
      "2463/2463 - 336s - loss: 0.0461 - acc: 0.9863 - val_loss: 0.0680 - val_acc: 0.9785\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.98687\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 15/100\n",
      "2463/2463 - 336s - loss: 0.0353 - acc: 0.9897 - val_loss: 0.0387 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.98687 to 0.99029, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 16/100\n",
      "2463/2463 - 355s - loss: 0.0307 - acc: 0.9913 - val_loss: 0.0379 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.99029\n",
      "Epoch 17/100\n",
      "2463/2463 - 338s - loss: 0.0289 - acc: 0.9910 - val_loss: 0.0386 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00017: val_acc improved from 0.99029 to 0.99052, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 18/100\n",
      "2463/2463 - 344s - loss: 0.0266 - acc: 0.9920 - val_loss: 0.0394 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.99052 to 0.99075, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 19/100\n",
      "2463/2463 - 343s - loss: 0.0243 - acc: 0.9928 - val_loss: 0.0386 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.99075 to 0.99132, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 20/100\n",
      "2463/2463 - 340s - loss: 0.0243 - acc: 0.9922 - val_loss: 0.0382 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.99132\n",
      "Epoch 21/100\n",
      "2463/2463 - 335s - loss: 0.0224 - acc: 0.9931 - val_loss: 0.0386 - val_acc: 0.9906\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.99132\n",
      "Epoch 22/100\n",
      "2463/2463 - 329s - loss: 0.0220 - acc: 0.9929 - val_loss: 0.0394 - val_acc: 0.9905\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.99132\n",
      "\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 23/100\n",
      "2463/2463 - 316s - loss: 0.0213 - acc: 0.9933 - val_loss: 0.0399 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.99132\n",
      "Epoch 24/100\n",
      "2463/2463 - 276s - loss: 0.0197 - acc: 0.9939 - val_loss: 0.0385 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.99132 to 0.99155, saving model to Beat_CLassification_Model.h5\n",
      "Epoch 25/100\n",
      "2463/2463 - 278s - loss: 0.0199 - acc: 0.9937 - val_loss: 0.0383 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.99155\n",
      "Epoch 26/100\n",
      "2463/2463 - 280s - loss: 0.0191 - acc: 0.9939 - val_loss: 0.0387 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.99155\n",
      "Epoch 27/100\n",
      "2463/2463 - 281s - loss: 0.0194 - acc: 0.9937 - val_loss: 0.0390 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.99155\n",
      "\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 28/100\n",
      "2463/2463 - 280s - loss: 0.0196 - acc: 0.9939 - val_loss: 0.0383 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.99155\n",
      "Epoch 29/100\n",
      "2463/2463 - 277s - loss: 0.0191 - acc: 0.9940 - val_loss: 0.0378 - val_acc: 0.9915\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.99155\n",
      "Epoch 00029: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f817a96730>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, epochs=100, verbose=2, callbacks=callbacks_list, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(chk_pnt_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = model.predict(X_test)\n",
    "#print(pred_test)\n",
    "pred_test = np.argmax(pred_test, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1_score(Y_test, pred_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test f1 score : 0.9255069882687508 \n"
     ]
    }
   ],
   "source": [
    "print(\"Test f1 score : %s \"% f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = accuracy_score(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy score : 0.98780376393203 \n"
     ]
    }
   ],
   "source": [
    "print(\"Test accuracy score : %s \"% acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18057    43    11     4     3]\n",
      " [   90   457     9     0     0]\n",
      " [   33     4  1393    17     1]\n",
      " [   21     2    14   125     0]\n",
      " [    9     0     6     0  1593]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(Y_test,pred_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     18118\n",
      "           1       0.90      0.82      0.86       556\n",
      "           2       0.97      0.96      0.97      1448\n",
      "           3       0.86      0.77      0.81       162\n",
      "           4       1.00      0.99      0.99      1608\n",
      "\n",
      "    accuracy                           0.99     21892\n",
      "   macro avg       0.94      0.91      0.93     21892\n",
      "weighted avg       0.99      0.99      0.99     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_test,pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
